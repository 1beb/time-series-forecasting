---
title: "Tidy Time Series & Forecasting in R"
author: "6. Introduction to forecasting"
toc: true
output:
  binb::monash:
    colortheme: monashwhite
    fig_width: 7
    fig_height: 3.5
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE,
  dev.args = list(pointsize = 11)
)
options(digits = 3, width = 67)
library(tidyverse)
library(fpp3)
usmelec <- as_tsibble(fpp2::usmelec) %>%
  rename(Month = index, Generation = value)
eu_retail <- as_tsibble(fpp2::euretail)
h02 <- tsibbledata::PBS %>%
  filter(ATC2 == "H02") %>%
  summarise(Cost = sum(Cost))
melsyd <- tsibbledata::ansett %>%
  filter(Airports == "MEL-SYD")
austa <- as_tsibble(fpp2::austa) %>%
  rename(Year = index, Visitors = value)
```

# What can we forecast?

## Forecasting is difficult

\full{hopecasts2}

## Forecasting is difficult

\full{bad_forecasts}

## What can we forecast?

\full{nasdaq-stock-market}

## What can we forecast?

\full{Forex2}

## What can we forecast?

\full{pills}

## What can we forecast?

\full{elecwires2}

## What can we forecast?

\full{AusBOM}

## What can we forecast?

\full{ts22015}

## What can we forecast?

\full{comet}

## Which is easiest to forecast?

 1. daily electricity demand in 3 days time
 2. timing of next Halley's comet appearance
 3. time of sunrise this day next year
 4. Google stock price tomorrow
 5. Google stock price in 6 months time
 6. maximum temperature tomorrow
 7. exchange rate of \$US/AUS next week
 8. total sales of drugs in Australian pharmacies next month

\pause

 - how do we measure "easiest"?
 - what makes something easy/difficult to forecast?

## Factors affecting forecastability

Something is easier to forecast if:

 - we have a good understanding of the factors that contribute to it
 - there is lots of data available;
 - the forecasts cannot affect the thing we are trying to forecast.
 - there is relatively low natural/unexplainable random variation.
 - the future is somewhat similar to the past

## Improving forecasts

\full{ncep-skill}

## CASE STUDY 1: Paperware company

\fontsize{12}{14}\sf

\begin{textblock}{7.6}(0.2,1.4)
\textbf{Problem:} Want forecasts of each of hundreds of
items. Series can be stationary, trended or seasonal. They currently
have a large forecasting program written in-house but it doesn't seem
to produce sensible forecasts. They want me to tell them what is
wrong and fix it.

\vspace*{0.1cm}

\textbf{Additional information}\vspace*{-0.2cm}\fontsize{12}{13.5}\sf
\begin{itemize}\itemsep=0cm\parskip=0cm
\item  Program  written in COBOL making numerical calculations limited. It is not possible to do any optimisation.
\item Their programmer has little experience in numerical computing.
\item They employ no statisticians and want the program to produce forecasts \rlap{automatically.}
\end{itemize}
\end{textblock}

\placefig{8}{1.4}{width=4.8cm}{tableware2}

## CASE STUDY 1: Paperware company

### Methods currently used

A
: 12 month average

C
: 6 month average

E
: straight line regression over last 12 months

G
: straight line regression over last 6 months

H
: average slope between last year's and this year's values.
  (Equivalent to differencing at lag 12 and taking mean.)

I
: Same as H except over 6 months.

K
: I couldn't understand the explanation.

## CASE STUDY 2: PBS

\full{pills}

## CASE STUDY 2: PBS

### The Pharmaceutical Benefits Scheme (PBS) is the Australian government drugs subsidy scheme.

  * Many drugs bought from pharmacies are subsidised to allow more equitable access to modern drugs.
  * The cost to government is determined by the number and types of drugs purchased. Currently nearly 1\% of GDP.
  * The total cost is budgeted based on forecasts of drug usage.

## CASE STUDY 2: PBS

\full{pbs2}

## CASE STUDY 2: PBS

  * In 2001: \$4.5 billion budget, under-forecasted by \$800 million.
  * Thousands of products. Seasonal demand.
  * Subject to covert marketing, volatile products, uncontrollable expenditure.
  * Although monthly data available for 10 years, data are aggregated to annual values, and only the first three years are used in estimating the forecasts.
  * All forecasts being done with the \texttt{FORECAST} function in MS-Excel!

## CASE STUDY 3: Car fleet company

**Client:** One of Australia's largest car fleet companies

**Problem:** how to forecast resale value of vehicles? How
should this affect leasing and sales policies?

\pause

### Additional information
 - They can provide a large amount of data on previous vehicles and their eventual resale values.
 - The resale values are currently estimated by a group of specialists. They see me as a threat and do not cooperate.

## CASE STUDY 4: Airline

\full{ansettlogo}

## CASE STUDY 4: Airline

```{r, echo=FALSE, fig.height=5}
melsyd %>%
  filter(Class == "Economy") %>%
  autoplot(Passengers) +
  labs(
    title = "Economy class passengers",
    subtitle = "Melbourne-Sydney",
    xlab = "Year"
  ) +
  ylab("Thousands")
```

## CASE STUDY 4: Airline

**Problem:** how to forecast passenger traffic on major routes?

### Additional information

  * They can provide a large amount of data on previous routes.
  * Traffic is affected by school holidays, special events such as
the Grand Prix, advertising campaigns, competition behaviour, etc.
  * They have a highly capable team of people who are able to do
most of the computing.

# The statistical forecasting perspective

## Sample futures

```{r austa1, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE, fig.width=9, fig.height=6}
fit <- austa %>% model(ETS())
```

```{r austa1a, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE, fig.width=9, fig.height=6}
sim <- fit %>%
  generate(h = 10, times = 10) %>%
  mutate(
    replicate = factor(.rep, levels = 1:10, labels = paste("Future", 1:10))
  )
ggplot(austa, aes(x = Year)) +
  geom_line(aes(y = Visitors, colour = "Data")) +
  geom_line(aes(y = .sim, colour = replicate), data = sim) +
  ylab("Millions of visitors") + xlab("Year") +
  ggtitle("Total international visitors to Australia") +
  scale_colour_manual(
    values = c("#000000", rainbow(10)),
    breaks = c("Data", paste("Future", 1:10)),
    name = " "
  )
```

## Forecast intervals

```{r austa2, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE, fig.width=8.6, fig.height=6}
fit %>%
  forecast(h = 10) %>%
  autoplot(austa) +
  ylab("Millions of visitors") + xlab("Year") +
  ggtitle("Forecasts of total international visitors to Australia")
```

## Statistical forecasting

\fontsize{14}{16}\sf

- Thing to be forecast: a random variable, $y_t$.
- Forecast distribution: If ${\cal I}$ is all observations, then $y_{t} |{\cal I}$ means ``the random variable $y_{t}$ given what we know in \rlap{${\cal I}$''.}
- The ``point forecast'' is the mean (or median) of $y_{t} |{\cal I}$
- The ``forecast variance'' is $\text{var}[y_{t} |{\cal I}]$
- A prediction interval or ``interval forecast'' is a range of values of $y_t$ with high \rlap{probability.}
- With time series, \rlap{${y}_{t|t-1} = y_t | \{y_1,y_2,\dots,y_{t-1}\}$. }
- $\hat{y}_{T+h|T} =\text{E}[y_{T+h} | y_1,\dots,y_T]$ (an $h$-step forecast taking account of all observations up to time $T$).

# Benchmark methods

## Some simple forecasting methods

```{r ausbeer, fig.height=4.6, echo=FALSE}
new_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
new_production %>% autoplot(Beer) +
  xlab("Year") + ylab("megalitres") +
  ggtitle("Australian quarterly beer production")
```

\begin{textblock}{7}(0.2,8.7)
\begin{alertblock}{}
\small{How would you forecast these series?}
\end{alertblock}
\end{textblock}

## Some simple forecasting methods

```{r pigs, fig.height=4.6, echo=FALSE}
aus_livestock %>%
  filter(
    between(year(Month), 1992, 1996),
    Animal == "Pigs", State == "Victoria"
  ) %>%
  autoplot(Count) +
  xlab("Year") + ylab("thousands") +
  ggtitle("Number of pigs slaughtered in Victoria, 1990-1995")
```

\begin{textblock}{7}(0.2,8.7)
\begin{alertblock}{}
\small{How would you forecast these series?}
\end{alertblock}
\end{textblock}

## Some simple forecasting methods

```{r dj, fig.height=4.6, echo=FALSE}
gafa_stock %>%
  filter(Symbol == "FB", Date >= ymd("2018-01-01")) %>%
  autoplot(Close) +
  labs(
    title = "Facebook closing stock price in 2018",
    x = NULL, y = "Closing price ($USD)"
  )
```

\begin{textblock}{7}(0.2,8.7)
\begin{alertblock}{}
\small{How would you forecast these series?}
\end{alertblock}
\end{textblock}

## Some simple forecasting methods
\fontsize{13}{14}\sf

### `MEAN(y)`: Average method

  * Forecast of all future values is equal to mean of historical data $\{y_1,\dots,y_T\}$.
  * Forecasts: $\hat{y}_{T+h|T} = \bar{y} = (y_1+\dots+y_T)/T$

```{r mean-method-explained, echo=FALSE, message=FALSE, warning=FALSE, fig.height = 3.3}
bricks <- aus_production %>%
  filter(!is.na(Bricks)) %>%
  mutate(average = mean(Bricks))

fc <- bricks %>%
  model(MEAN(Bricks)) %>%
  forecast(h = "5 years")

bricks %>%
  ggplot(aes(x = Quarter, y = Bricks)) +
  geom_line() +
  geom_line(aes(y = average), colour = "blue", linetype = "dashed") +
  geom_line(aes(y = Bricks), data = fc, colour = "blue") +
  ggtitle("Clay brick production in Australia")
```

## Some simple forecasting methods
\fontsize{13}{14}\sf

### `NAIVE(y)`: Naïve method

  * Forecasts equal to last observed value.
  * Forecasts: $\hat{y}_{T+h|T} =y_T$.
  * Consequence of efficient market hypothesis.

```{r naive-method-explained, echo = FALSE, warning = FALSE, fig.height = 3.3}
bricks %>%
  filter(!is.na(Bricks)) %>%
  model(NAIVE(Bricks)) %>%
  forecast(h = "5 years") %>%
  autoplot(filter(bricks, year(Quarter) > 1990), level = NULL) +
  geom_point(data = slice(bricks, n()), colour = "blue") +
  ggtitle("Clay brick production in Australia")
```

## Some simple forecasting methods
\fontsize{13}{14}\sf

### `SNAIVE(y ~ lag(m))`: Seasonal naïve method

  * Forecasts equal to last value from same season.
  * Forecasts: $\hat{y}_{T+h|T} =y_{T+h-m(k+1)}$, where $m=$ seasonal period and $k$ is the integer part of $(h-1)/m$.

```{r snaive-method-explained, echo = FALSE, warning = FALSE, fig.height = 3.3}
bricks %>%
  model(SNAIVE(Bricks ~ lag("year"))) %>%
  forecast(h = "5 years") %>%
  autoplot(filter(bricks, year(Quarter) > 1990), level = NULL) +
  geom_point(data = slice(bricks, (n() - 3):n()), colour = "blue") +
  ggtitle("Clay brick production in Australia")
```

## Some simple forecasting methods
\fontsize{13}{14}\sf

### `RW(y ~ drift())`: Drift method

 * Forecasts equal to last value plus average change.
 * Forecasts:\vspace*{-.7cm}

 \begin{align*}
 \hat{y}_{T+h|T} & =  y_{T} + \frac{h}{T-1}\sum_{t=2}^T (y_t-y_{t-1})\\
                 & = y_T + \frac{h}{T-1}(y_T -y_1).
 \end{align*}\vspace*{-0.2cm}

   * Equivalent to extrapolating a line drawn between first and last observations.

## Some simple forecasting methods

### Drift method

```{r drift-method-explained, echo = FALSE, warning = FALSE}
aus_production %>%
  filter(!is.na(Bricks)) %>%
  model(RW(Bricks ~ drift())) %>%
  forecast(h = "5 years") %>%
  autoplot(aus_production, level = NULL) +
  geom_line(
    data = slice(aus_production, range(cumsum(!is.na(Bricks)))),
    linetype = "dashed", colour = "blue"
  ) +
  ggtitle("Clay brick production in Australia")
```

## Model fitting

The `model()` function trains models to data.

\fontsize{10}{11}\sf

```{r beer-model}
# Fit the models
beer_fit <- aus_production %>%
  model(
    Mean = MEAN(Beer),
    `Naïve` = NAIVE(Beer),
    `Seasonal naïve` = SNAIVE(Beer),
    Drift = RW(Beer ~ drift())
  )
beer_fit
```

\vspace*{-0.2cm}\begin{alertblock}{}
A \texttt{mable} is a model table, each cell corresponds to a fitted model.
\end{alertblock}

## Producing forecasts

\fontsize{10}{13}\sf

```{r beer-fc, echo = TRUE, dependson='beer-model'}
beer_fc <- beer_fit %>%
  forecast(h = 11)
```

```{r beer-fbl, echo = FALSE, dependson='beer-fc'}
print(beer_fc, n = 4)
```

\begin{alertblock}{}
A \texttt{fable} is a forecast table with point forecasts and distributions.
\end{alertblock}

## Visualising forecasts

\footnotesize

```{r beer-fc-plot, warning=FALSE, message=FALSE, fig.height=3}
beer_fc %>%
  autoplot(aus_production, level = NULL) +
  ggtitle("Forecasts for quarterly beer production") +
  xlab("Year") + ylab("Megalitres") +
  guides(colour=guide_legend(title="Forecast"))
```

## Facebook closing stock price

\fontsize{9}{10}\sf

```{r fbf, eval=FALSE}
# Extract training data
fb_stock <- gafa_stock %>%
  filter(Symbol == "FB") %>%
  mutate(trading_day = row_number()) %>%
  update_tsibble(index = trading_day, regular = TRUE)
# Specify, estimate and forecast
fb_stock %>%
  model(
    Mean = MEAN(Close),
    `Naïve` = NAIVE(Close),
    Drift = RW(Close ~ drift())
  ) %>%
  forecast(h = 100) %>%
  autoplot(fb_stock, level = NULL) +
  ggtitle("Facebook closing stock price") +
  xlab("Day") + ylab("") +
  guides(colour = guide_legend(title = "Forecast"))
```

## Facebook closing stock price

```{r fb-fc-plot, echo=FALSE, fig.height=4.6}
# Extract training data
fb_stock <- gafa_stock %>%
  filter(Symbol == "FB") %>%
  mutate(trading_day = row_number()) %>%
  update_tsibble(index = trading_day, regular = TRUE)
# Specify, estimate and forecast
fb_stock %>%
  model(
    Mean = MEAN(Close),
    `Naïve` = NAIVE(Close),
    Drift = RW(Close ~ drift())
  ) %>%
  forecast(h = 100) %>%
  autoplot(fb_stock, level = NULL) +
  ggtitle("Facebook closing stock price") +
  xlab("Day") + ylab("") +
  guides(colour = guide_legend(title = "Forecast"))
```

# Lab Session 11
## Lab Session 11

 * Produce forecasts using an appropriate benchmark method for household wealth (`hh_budget`). Plot the results using `autoplot()`.
 * Produce forecasts using an appropriate benchmark method for Australian takeaway food turnover (`aus_retail`). Plot the results using `autoplot()`.

# Residual diagnostics

## Fitted values

 - $\hat{y}_{t|t-1}$ is the forecast of $y_t$ based on observations $y_1,\dots,y_t$.
 - We call these "fitted values".
 - Sometimes drop the subscript: $\hat{y}_t \equiv \hat{y}_{t|t-1}$.
 - Often not true forecasts since parameters are estimated on all data.

### For example:

 - $\hat{y}_{t} = \bar{y}$ for average method.
 - $\hat{y}_{t} = y_{t-1} + (y_{T}-y_1)/(T-1)$ for drift method.

## Forecasting residuals

\begin{block}{}
\textbf{Residuals in forecasting:} difference between observed value and its fitted value: $e_t = y_t-\hat{y}_{t|t-1}$.
\end{block}
\pause\fontsize{13}{15}\sf

\alert{Assumptions}

  1. $\{e_t\}$ uncorrelated. If they aren't, then information left in  residuals that should be used in computing forecasts.
  2. $\{e_t\}$ have mean zero. If they don't, then forecasts are biased.

\pause

\alert{Useful properties} (for prediction intervals)

  3. $\{e_t\}$ have constant variance.
  4. $\{e_t\}$ are normally distributed.

## Facebook closing stock price

```{r}
fb_stock %>%
  autoplot(Close)
```

## Facebook closing stock price

\alert{Na\"{\i}ve forecast:}

\[\hat{y}_{t|t-1}= y_{t-1}\]\pause
\[e_t = y_t - \hat{y}_{t|t-1} = y_t-y_{t-1}\]\pause

\begin{alertblock}{}
Note: $e_t$ are one-step-forecast residuals
\end{alertblock}

## Facebook closing stock price
\fontsize{10}{10}\sf

```{r augment}
fit <- fb_stock %>% model(NAIVE(Close))
augment(fit)
```

## Facebook closing stock price
\fontsize{10}{10}\sf

```{r dj4, echo=TRUE, warning=FALSE, fig.height=3.7}
augment(fit) %>%
  ggplot(aes(x = trading_day)) +
  geom_line(aes(y = Close, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted"))
```

## Facebook closing stock price
\fontsize{10}{10}\sf

```{r dj4a, echo=TRUE, warning=FALSE, fig.height=3.7}
augment(fit) %>%
  filter(trading_day > 1100) %>%
  ggplot(aes(x = trading_day)) +
  geom_line(aes(y = Close, colour = "Data")) +
  geom_line(aes(y = .fitted, colour = "Fitted"))
```

## Facebook closing stock price
\fontsize{10}{10}\sf

```{r dj5, echo=TRUE, warning = FALSE}
augment(fit) %>%
  autoplot(.resid) + xlab("Day") + ylab("") +
  ggtitle("Residuals from naïve method")
```

## Facebook closing stock price
\fontsize{11}{11}\sf

```{r dj6, warning=FALSE}
augment(fit) %>%
  ggplot(aes(x = .resid)) +
  geom_histogram(bins = 150) +
  ggtitle("Histogram of residuals")
```

## Facebook closing stock price
\fontsize{11}{11}\sf

```{r dj7}
augment(fit) %>%
  ACF(.resid) %>%
  autoplot() + ggtitle("ACF of residuals")
```

## ACF of residuals

  * We assume that the residuals are white noise (uncorrelated, mean zero, constant variance). If they aren't, then there is information left in  the residuals that should be used in computing forecasts.

  * So a standard residual diagnostic is to check the ACF of the residuals of a forecasting method.

  * We *expect* these to look like white noise.

## Combined diagnostic graph
\fontsize{11}{11}\sf

```{r dj8}
fit %>% gg_tsresiduals()
```

## Ljung-Box test
\fontsize{13}{15}\sf

Test whether *whole set* of $r_{k}$ values is significantly different from zero set.

\begin{block}{}
\centerline{$\displaystyle
 Q = T(T+2) \sum_{k=1}^h (T-k)^{-1}r_k^2$}
where $h=$ max lag and $T=$ \# observations.
\end{block}

  * If each $r_k$ close to zero, $Q$ will be **small**.
  * If some $r_k$ values large ($+$ or $-$), $Q$ will be **large**.
  * My preferences: $h=10$ for non-seasonal data, $h=2m$ for seasonal data.
  * If data are WN, $Q \sim \chi^2$ with $(h - K)$ degrees of freedom where $K=$ no.\ parameters in model.
  * When applied to raw data, set $K=0$.

## Ljung-Box test
\fontsize{12}{13}\sf

\begin{block}{}
\centerline{$\displaystyle
 Q = T(T+2) \sum_{k=1}^h (T-k)^{-1}r_k^2$}
where $h=$ max lag and $T=$ \# observations.
\end{block}

\fontsize{11}{11}\sf

```{r dj9extra, echo=FALSE, fig.height=1.5}
augment(fit) %>%
  ACF(.resid, lag_max = 10) %>%
  autoplot() + ggtitle("ACF of residuals")
```

\vspace*{-0.3cm}


```{r dj9, echo=TRUE}
# lag=h and dof=K
augment(fit) %>%
  features(.resid, ljung_box, dof = 0, lag = 10)
```

# Lab Session 12
## Lab Session 12

  * Compute seasonal naïve forecasts for quarterly Australian beer production.

  * Test if the residuals are white noise. What do you conclude?

# Forecast accuracy measures

## Training and test sets

```{r traintest, fig.height=1, echo=FALSE, cache=TRUE}
train <- 1:18
test <- 19:24
par(mar = c(0, 0, 0, 0))
plot(0, 0, xlim = c(0, 26), ylim = c(0, 2), xaxt = "n", yaxt = "n", bty = "n", xlab = "", ylab = "", type = "n")
arrows(0, 0.5, 25, 0.5, 0.05)
points(train, train * 0 + 0.5, pch = 19, col = "blue")
points(test, test * 0 + 0.5, pch = 19, col = "red")
text(26, 0.5, "time")
text(10, 1, "Training data", col = "blue")
text(21, 1, "Test data", col = "red")
```

  * A model which fits the training data well will not necessarily forecast well.
  * Forecast accuracy is based only on the test set.

### Forecast errors

Forecast "error": the difference between an observed value and its forecast.
$$
  e_{T+h} = y_{T+h} - \hat{y}_{T+h|T},
$$
where the training data is given by $\{y_1,\dots,y_T\}$

## Measures of forecast accuracy

```{r beer-fc-1, echo=FALSE, fig.height=4}
train <- aus_production %>%
  filter(between(year(Quarter), 1992, 2007))
beer <- aus_production %>%
  filter(year(Quarter) >= 1992)
train %>%
  model(
    ets = ETS(Beer),
    arima = ARIMA(Beer)
  ) %>%
  forecast(h=11) %>%
  autoplot(beer, level = NULL) +
    ggtitle("Forecasts for quarterly beer production") +
    xlab("Year") + ylab("Megalitres") +
    guides(colour=guide_legend(title="Forecast"))
```

## Measures of forecast accuracy

\begin{tabular}{rl}
$y_{T+h}=$ & $(T+h)$th observation, $h=1,\dots,H$ \\
$\pred{y}{T+h}{T}=$ & its forecast based on data up to time $T$. \\
$e_{T+h} =$  & $y_{T+h} - \pred{y}{T+h}{T}$
\end{tabular}

\begin{align*}
\text{MAE} &= \text{mean}(|e_{T+h}|) \\[-0.2cm]
\text{MSE} &= \text{mean}(e_{T+h}^2) \qquad
&&\text{RMSE} &= \sqrt{\text{mean}(e_{T+h}^2)} \\[-0.1cm]
\text{MAPE} &= 100\text{mean}(|e_{T+h}|/ |y_{T+h}|)
\end{align*}\pause

  * MAE, MSE, RMSE are all scale dependent.
  * MAPE is scale independent but is only sensible if $y_t\gg 0$ for all $t$, and $y$ has a natural zero.

## Measures of forecast accuracy

\begin{block}{Mean Absolute Scaled Error}
$$
\text{MASE} = \text{mean}(|e_{T+h}|/Q)
$$
where $Q$ is a stable measure of the scale of the time series $\{y_t\}$.
\end{block}
Proposed by Hyndman and Koehler (IJF, 2006).

For non-seasonal time series,
$$
  Q = (T-1)^{-1}\sum_{t=2}^T |y_t-y_{t-1}|
$$
works well. Then MASE is equivalent to MAE relative to a naïve method.

\vspace*{10cm}

## Measures of forecast accuracy

\begin{block}{Mean Absolute Scaled Error}
$$
\text{MASE} = \text{mean}(|e_{T+h}|/Q)
$$
where $Q$ is a stable measure of the scale of the time series $\{y_t\}$.
\end{block}
Proposed by Hyndman and Koehler (IJF, 2006).

For seasonal time series,
$$
  Q = (T-m)^{-1}\sum_{t=m+1}^T |y_t-y_{t-m}|
$$
works well. Then MASE is equivalent to MAE relative to a seasonal naïve method.

\vspace*{10cm}

## Measures of forecast accuracy

\fontsize{10}{10}\sf

```{r beer-test-accuracy}
recent_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
train <- recent_production %>% filter(year(Quarter) <= 2007)
beer_fit <- train %>%
  model(
    ets = ETS(Beer),
    arima = ARIMA(Beer)
  )
beer_fc <- forecast(beer_fit, h="4 years")
accuracy(beer_fc, aus_production)
```

# Lab Session 13
## Lab Session 13

 * Create a training set for household wealth (`hh_budget`) by witholding the last four years as a test set.
 * Fit all the appropriate benchmark methods to the training set and forecast the periods covered by the test set.
 * Compute the accuracy of your forecasts. Which method does best?
 * Repeat the exercise using the Australian takeaway food turnover data (`aus_retail`) with a test set of four years.

