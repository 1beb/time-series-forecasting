---
title: "Tidy Time Series & Forecasting in R"
date: "robjhyndman.com/workshop2020"
author: "6. Automatic forecasting algorithms"
toc: true
output:
  binb::monash:
    colortheme: monashwhite
    fig_width: 7
    fig_height: 3.5
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE,
  dev.args = list(pointsize = 11)
)
options(digits = 3, width = 66)
library(tidyverse)
library(fpp3)
usmelec <- as_tsibble(fpp2::usmelec) %>%
  rename(Month = index, Generation = value)
us_change <- readr::read_csv("https://otexts.com/fpp3/extrafiles/us_change.csv")  %>%
  mutate(Time = yearquarter(Time)) %>%
  as_tsibble(index = Time)
eu_retail <- as_tsibble(fpp2::euretail)
h02 <- tsibbledata::PBS %>%
  filter(ATC2 == "H02") %>%
  summarise(Cost = sum(Cost))
melsyd <- tsibbledata::ansett %>%
  filter(Airports == "MEL-SYD")
austa <- as_tsibble(fpp2::austa) %>%
  rename(Year = index, Visitors = value)
```


# What can we forecast?

## Forecasting is difficult

\full{hopecasts2}

## Forecasting is difficult

\full{bad_forecasts}

## What can we forecast?

\full{nasdaq-stock-market}

## What can we forecast?

\full{Forex2}

## What can we forecast?

\full{pills}

## What can we forecast?

\full{elecwires2}

## What can we forecast?

\full{AusBOM}

## What can we forecast?

\full{ts22015}

## What can we forecast?

\full{comet}

## Which is easiest to forecast?

 1. daily electricity demand in 3 days time
 2. timing of next Halley's comet appearance
 3. time of sunrise this day next year
 4. Google stock price tomorrow
 5. Google stock price in 6 months time
 6. maximum temperature tomorrow
 7. exchange rate of \$US/AUS next week
 8. total sales of drugs in Australian pharmacies next month

\pause

 - how do we measure "easiest"?
 - what makes something easy/difficult to forecast?

## Factors affecting forecastability

Something is easier to forecast if:

 - we have a good understanding of the factors that contribute to it
 - there is lots of data available;
 - the forecasts cannot affect the thing we are trying to forecast.
 - there is relatively low natural/unexplainable random variation.
 - the future is somewhat similar to the past

## Improving forecasts

\full{ncep-skill}

# Some case studies

## CASE STUDY 1: Paperware company

\fontsize{12}{14}\sf

\begin{textblock}{7.6}(0.2,1.4)
\textbf{Problem:} Want forecasts of each of hundreds of
items. Series can be stationary, trended or seasonal. They currently
have a large forecasting program written in-house but it doesn't seem
to produce sensible forecasts. They want me to tell them what is
wrong and fix it.

\vspace*{0.1cm}

\textbf{Additional information}\vspace*{-0.2cm}\fontsize{12}{13.5}\sf
\begin{itemize}\itemsep=0cm\parskip=0cm
\item  Program  written in COBOL making numerical calculations limited. It is not possible to do any optimisation.
\item Their programmer has little experience in numerical computing.
\item They employ no statisticians and want the program to produce forecasts \rlap{automatically.}
\end{itemize}
\end{textblock}

\placefig{8}{1.4}{width=4.8cm}{tableware2}


## CASE STUDY 1: Paperware company

### Methods currently used

A
: 12 month average

C
: 6 month average

E
: straight line regression over last 12 months

G
: straight line regression over last 6 months

H
: average slope between last year's and this year's values.
  (Equivalent to differencing at lag 12 and taking mean.)

I
: Same as H except over 6 months.

K
: I couldn't understand the explanation.

## CASE STUDY 2: PBS

\full{pills}


## CASE STUDY 2: PBS

### The Pharmaceutical Benefits Scheme (PBS) is the Australian government drugs subsidy scheme.

  * Many drugs bought from pharmacies are subsidised to allow more equitable access to modern drugs.
  * The cost to government is determined by the number and types of drugs purchased. Currently nearly 1\% of GDP.
  * The total cost is budgeted based on forecasts of drug usage.

## CASE STUDY 2: PBS

\full{pbs2}

## CASE STUDY 2: PBS

  * In 2001: \$4.5 billion budget, under-forecasted by \$800 million.
  * Thousands of products. Seasonal demand.
  * Subject to covert marketing, volatile products, uncontrollable expenditure.
  * Although monthly data available for 10 years, data are aggregated to annual values, and only the first three years are used in estimating the forecasts.
  * All forecasts being done with the \texttt{FORECAST} function in MS-Excel!


## CASE STUDY 3: Car fleet company

**Client:** One of Australia's largest car fleet companies

**Problem:** how to forecast resale value of vehicles? How
should this affect leasing and sales policies?

\pause

### Additional information
 - They can provide a large amount of data on previous vehicles and their eventual resale values.
 - The resale values are currently estimated by a group of specialists. They see me as a threat and do not cooperate.



## CASE STUDY 4: Airline

\full{ansettlogo}


## CASE STUDY 4: Airline

```{r, echo=FALSE, fig.height=5}
melsyd %>%
  filter(Class == "Economy") %>%
  autoplot(Passengers) +
  labs(
    title = "Economy class passengers",
    subtitle = "Melbourne-Sydney",
    xlab = "Year"
  ) +
  ylab("Thousands")
```


## CASE STUDY 4: Airline

```{r, echo=FALSE, fig.height=5}
melsyd %>%
  filter(Class == "Economy") %>%
  autoplot(Passengers) +
  labs(
    title = "Economy class passengers",
    subtitle = "Melbourne-Sydney"
  ) +
  ylab("Thousands")
```

\begin{textblock}{4.2}(7,6.3)
\begin{alertblock}{}
Not the real data! Or is it?
\end{alertblock}
\end{textblock}

## CASE STUDY 4: Airline

**Problem:** how to forecast passenger traffic on major routes?

### Additional information

  * They can provide a large amount of data on previous routes.
  * Traffic is affected by school holidays, special events such as
the Grand Prix, advertising campaigns, competition behaviour, etc.
  * They have a highly capable team of people who are able to do
most of the computing.


# The statistical forecasting perspective

## Sample futures

```{r austa1, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE, fig.width=9, fig.height=6}
fit <- austa %>% model(ETS())
```

```{r austa1a, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE, fig.width=9, fig.height=6}
sim <- fit %>% generate(h = 10, times = 10) %>%
  mutate(
    replicate = factor(.rep, levels = 1:10, labels = paste("Future", 1:10))
  )
ggplot(austa, aes(x = Year)) +
  geom_line(aes(y = Visitors, colour = "Data")) +
  geom_line(aes(y = .sim, colour = replicate), data = sim) +
  ylab("Millions of visitors") + xlab("Year") +
  ggtitle("Total international visitors to Australia") +
  scale_colour_manual(values = c("#000000", rainbow(10)),
                      breaks = c("Data", paste("Future", 1:10)),
                      name = " ")
```

## Forecast intervals

```{r austa2, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE, fig.width=8.6, fig.height=6}
fit %>%
  forecast(h = 10) %>%
  autoplot(austa) +
  ylab("Millions of visitors") + xlab("Year") +
  ggtitle("Forecasts of total international visitors to Australia")
```


## Statistical forecasting

\fontsize{14}{16}\sf

- Thing to be forecast: a random variable, $y_t$.
- Forecast distribution: If ${\cal I}$ is all observations, then $y_{t} |{\cal I}$ means ``the random variable $y_{t}$ given what we know in \rlap{${\cal I}$''.}
- The ``point forecast'' is the mean (or median) of $y_{t} |{\cal I}$
- The ``forecast variance'' is $\text{var}[y_{t} |{\cal I}]$
- A prediction interval or ``interval forecast'' is a range of values of $y_t$ with high \rlap{probability.}
- With time series, \rlap{${y}_{t|t-1} = y_t | \{y_1,y_2,\dots,y_{t-1}\}$. }
- $\hat{y}_{T+h|T} =\text{E}[y_{T+h} | y_1,\dots,y_T]$ (an $h$-step forecast taking account of all observations up to time $T$).


# Forecast accuracy measures

## Training and test sets

```{r traintest, fig.height=1, echo=FALSE, cache=TRUE}
train = 1:18
test = 19:24
par(mar=c(0,0,0,0))
plot(0,0,xlim=c(0,26),ylim=c(0,2),xaxt="n",yaxt="n",bty="n",xlab="",ylab="",type="n")
arrows(0,0.5,25,0.5,0.05)
points(train, train*0+0.5, pch=19, col="blue")
points(test,  test*0+0.5,  pch=19, col="red")
text(26,0.5,"time")
text(10,1,"Training data",col="blue")
text(21,1,"Test data",col="red")
```

  * A model which fits the training data well will not necessarily forecast well.
  * Forecast accuracy is based only on the test set.

### Forecast errors

Forecast "error": the difference between an observed value and its forecast.
$$
  e_{T+h} = y_{T+h} - \hat{y}_{T+h|T},
$$
where the training data is given by $\{y_1,\dots,y_T\}$

## Measures of forecast accuracy

```{r beer-fc-1, echo=FALSE, fig.height=4}
train <- aus_production %>%
  filter(between(year(Quarter), 1992, 2007))
beer <- aus_production %>%
  filter(year(Quarter) >= 1992)
train %>%
  model(
    ets = ETS(Beer),
    arima = ARIMA(Beer)
  ) %>%
  forecast(h=11) %>%
  autoplot(beer, level = NULL) +
    ggtitle("Forecasts for quarterly beer production") +
    xlab("Year") + ylab("Megalitres") +
    guides(colour=guide_legend(title="Forecast"))
```

## Measures of forecast accuracy

\begin{tabular}{rl}
$y_{T+h}=$ & $(T+h)$th observation, $h=1,\dots,H$ \\
$\pred{y}{T+h}{T}=$ & its forecast based on data up to time $T$. \\
$e_{T+h} =$  & $y_{T+h} - \pred{y}{T+h}{T}$
\end{tabular}

\begin{align*}
\text{MAE} &= \text{mean}(|e_{T+h}|) \\[-0.2cm]
\text{MSE} &= \text{mean}(e_{T+h}^2) \qquad
&&\text{RMSE} &= \sqrt{\text{mean}(e_{T+h}^2)} \\[-0.1cm]
\text{MAPE} &= 100\text{mean}(|e_{T+h}|/ |y_{T+h}|)
\end{align*}\pause

  * MAE, MSE, RMSE are all scale dependent.
  * MAPE is scale independent but is only sensible if $y_t\gg 0$ for all $t$, and $y$ has a natural zero.

## Measures of forecast accuracy

\begin{block}{Mean Absolute Scaled Error}
$$
\text{MASE} = \text{mean}(|e_{T+h}|/Q)
$$
where $Q$ is a stable measure of the scale of the time series $\{y_t\}$.
\end{block}
Proposed by Hyndman and Koehler (IJF, 2006).

For non-seasonal time series,
$$
  Q = (T-1)^{-1}\sum_{t=2}^T |y_t-y_{t-1}|
$$
works well. Then MASE is equivalent to MAE relative to a naïve method.

\vspace*{10cm}

## Measures of forecast accuracy

\begin{block}{Mean Absolute Scaled Error}
$$
\text{MASE} = \text{mean}(|e_{T+h}|/Q)
$$
where $Q$ is a stable measure of the scale of the time series $\{y_t\}$.
\end{block}
Proposed by Hyndman and Koehler (IJF, 2006).

For seasonal time series,
$$
  Q = (T-m)^{-1}\sum_{t=m+1}^T |y_t-y_{t-m}|
$$
works well. Then MASE is equivalent to MAE relative to a seasonal naïve method.

\vspace*{10cm}

## Measures of forecast accuracy

\fontsize{10}{10}\sf

```{r beer-test-accuracy}
recent_production <- aus_production %>%
  filter(year(Quarter) >= 1992)
train <- recent_production %>% filter(year(Quarter) <= 2007)
beer_fit <- train %>%
  model(
    ets = ETS(Beer),
    arima = ARIMA(Beer)
  )
beer_fc <- forecast(beer_fit, h="4 years")
accuracy(beer_fc, aus_production)
```
